"""
AIåˆ†ææ¨¡å— - KDASè¯åˆ¸åˆ†æå·¥å…·

è´Ÿè´£å¤„ç†æ‰€æœ‰AIç›¸å…³çš„åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- AIæ™ºèƒ½æ¨èï¼ˆæ—¥æœŸæ¨èï¼‰
- AIçŠ¶æ€åˆ†æï¼ˆKDASçŠ¶æ€åˆ†æï¼‰
- åˆ†ææ–‡æœ¬æ ¼å¼åŒ–å’Œæ ·å¼å¤„ç†
- AIé¡¾é—®å®ä¾‹ç®¡ç†
- é”™è¯¯å¤„ç†å’Œå¤‡ç”¨æ–¹æ¡ˆ

ä½œè€…ï¼šKDASå›¢é˜Ÿ
ç‰ˆæœ¬ï¼š2.0 (æ¨¡å—åŒ–é‡æ„ç‰ˆæœ¬)
"""

import os
import re
import json
import asyncio
import streamlit as st
from datetime import datetime, timedelta

# === KDASåŒ…å¯¼å…¥ä¸åˆå§‹åŒ– ===
try:
    import sys
    sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
    from kdas import KDASAIAdvisor, KDASAnalyzer, get_ai_advisor, AIRecommendationEngine
    AI_ADVISOR_AVAILABLE = True
except ImportError:
    AI_ADVISOR_AVAILABLE = False
    KDASAIAdvisor = None
    KDASAnalyzer = None
    get_ai_advisor = None
    AIRecommendationEngine = None

class AIAnalysisManager:
    """AIåˆ†æç®¡ç†å™¨ç±»ï¼Œå°è£…æ‰€æœ‰AIç›¸å…³åŠŸèƒ½"""
    
    def __init__(self):
        """åˆå§‹åŒ–AIåˆ†æç®¡ç†å™¨"""
        self.ai_available = AI_ADVISOR_AVAILABLE
        
        # æ–‡æœ¬æ ·å¼è§„åˆ™é…ç½®
        self.styling_rules = [
            ('å¤šå¤´', 'ğŸŸ¢ **å¤šå¤´**'),
            ('ç©ºå¤´', 'ğŸ”´ **ç©ºå¤´**'),
            ('æ”¯æ’‘ä½', 'ğŸŸ¢ **æ”¯æ’‘ä½**'),
            ('å‹åŠ›ä½', 'ğŸ”´ **å‹åŠ›ä½**'),
            ('é˜»åŠ›ä½', 'ğŸ”´ **é˜»åŠ›ä½**'),
            ('çªç ´', 'âš¡ **çªç ´**'),
            ('è¶‹åŠ¿ç¡®è®¤', 'âœ… **è¶‹åŠ¿ç¡®è®¤**'),
            ('è¶‹åŠ¿åè½¬', 'ğŸ”„ **è¶‹åŠ¿åè½¬**'),
            ('æƒ…ç»ªå®£æ³„', 'ğŸ˜± **æƒ…ç»ªå®£æ³„**'),
            ('éœ‡è¡', 'ğŸ“Š **éœ‡è¡**'),
            ('æ•´ç†', 'â¸ï¸ **æ•´ç†**'),
            ('é£é™©', 'âš ï¸ **é£é™©**'),
            ('å»ºè®®', 'ğŸ’¡ **å»ºè®®**'),
            ('ç­–ç•¥', 'ğŸ¯ **ç­–ç•¥**'),
            ('å…³é”®ä½', 'ğŸ”‘ **å…³é”®ä½**'),
            ('æ”¶æ•›', 'ğŸ“ **æ”¶æ•›**'),
            ('å‘æ•£', 'ğŸ“ **å‘æ•£**'),
            ('è§‚æœ›', 'ğŸ‘€ **è§‚æœ›**'),
            ('å…¥åœº', 'ğŸš€ **å…¥åœº**'),
            ('æ­¢æŸ', 'ğŸ›‘ **æ­¢æŸ**'),
            ('æ­¢ç›ˆ', 'âœ¨ **æ­¢ç›ˆ**'),
            ('KDAS', 'ğŸ“Š **KDAS**'),
            ('å‡çº¿', 'ğŸ“ˆ **å‡çº¿**'),
            ('å¤šç©ºåŠ›é‡', 'âš–ï¸ **å¤šç©ºåŠ›é‡**'),
            ('è¶‹åŠ¿è¡Œè¿›', 'ğŸ“ˆ **è¶‹åŠ¿è¡Œè¿›**'),
            ('è¶‹åŠ¿è¡°ç«­', 'ğŸ“‰ **è¶‹åŠ¿è¡°ç«­**'),
            ('å¸‚åœºä¸€è‡´æ€§', 'ğŸ¯ **å¸‚åœºä¸€è‡´æ€§**'),
            ('æƒ…ç»ªç§¯ç´¯', 'ğŸ“Š **æƒ…ç»ªç§¯ç´¯**'),
            ('ç›˜æ•´', 'ğŸ“Š **ç›˜æ•´**'),
            ('å¼ºåŠ¿', 'ğŸ’ª **å¼ºåŠ¿**'),
            ('å¼±åŠ¿', 'ğŸ“‰ **å¼±åŠ¿**'),
            ('é«˜ä½', 'â¬†ï¸ **é«˜ä½**'),
            ('ä½ä½', 'â¬‡ï¸ **ä½ä½**')
        ]
        
        # JSONå­—æ®µæ˜ å°„é…ç½®
        self.field_mapping = {
            'çŠ¶æ€': ('ğŸ“Š', 'KDASçŠ¶æ€åˆ†æ'),
            'å¤šç©ºåŠ›é‡åˆ†æ': ('âš–ï¸', 'å¤šç©ºåŠ›é‡å¯¹æ¯”'),
            'è¶‹åŠ¿æ–¹å‘åˆ¤æ–­': ('ğŸ“ˆ', 'è¶‹åŠ¿æ–¹å‘åˆ¤æ–­'),
            'äº¤æ˜“å»ºè®®': ('ğŸ’¡', 'äº¤æ˜“ç­–ç•¥å»ºè®®'),
            'é£é™©æç¤º': ('âš ï¸', 'é£é™©è¯„ä¼°æç¤º'),
            'ç½®ä¿¡åº¦': ('ğŸ¯', 'åˆ†æç½®ä¿¡åº¦')
        }
        
        # æ®µè½æ ¼å¼åŒ–å›¾æ ‡é…ç½®
        self.paragraph_icons = {
            '1': 'ğŸ“Š', '2': 'âš–ï¸', '3': 'ğŸ“ˆ', 
            '4': 'ğŸ’¡', '5': 'ğŸ¯', '6': 'âš ï¸'
        }
    
    def get_ai_advisor_instance(self, api_key, model):
        """è·å–AIé¡¾é—®å®ä¾‹"""
        if not self.ai_available:
            return None
            
        try:
            # ä½¿ç”¨kdasåŒ…çš„get_ai_advisorå‡½æ•°
            advisor = get_ai_advisor(api_key, model)
            return advisor
        except Exception as e:
            st.warning(f"åˆ›å»ºAIé¡¾é—®å®ä¾‹å¤±è´¥: {str(e)}")
            return None
    
    def generate_ai_recommendation(self, symbol, security_type, api_key, model, get_security_name_func, get_security_data_func):
        """
        ç”ŸæˆAIæ—¥æœŸæ¨è
        
        Args:
            symbol: è¯åˆ¸ä»£ç 
            security_type: è¯åˆ¸ç±»å‹
            api_key: APIå¯†é’¥
            model: AIæ¨¡å‹
            get_security_name_func: è·å–è¯åˆ¸åç§°çš„å‡½æ•°
            get_security_data_func: è·å–è¯åˆ¸æ•°æ®çš„å‡½æ•°
        """
        if not self.ai_available:
            return {
                'success': False,
                'error': 'AIåŠŸèƒ½ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥kdasåŒ…æ˜¯å¦æ­£ç¡®å®‰è£…'
            }
        
        try:
            # è·å–è¯åˆ¸åç§°
            security_name = get_security_name_func(symbol, security_type)
            
            # ç”Ÿæˆä¸´æ—¶æ—¥æœŸç”¨äºæ•°æ®è·å–
            temp_dates = {f'day{i+1}': (datetime.now() - timedelta(days=30*i)).strftime('%Y%m%d') for i in range(5)}
            
            # è·å–åˆ†ææ•°æ®
            analysis_data = get_security_data_func(symbol, temp_dates, security_type)
            
            if analysis_data.empty:
                return {
                    'success': False,
                    'error': f'æœªæ‰¾åˆ°è¯¥{security_type}çš„æ•°æ®ï¼Œè¯·æ£€æŸ¥{security_type}ä»£ç æ˜¯å¦æ­£ç¡®'
                }
            
            ai_engine = AIRecommendationEngine(api_key, model)
            result = ai_engine.generate_kdas_recommendation(
                analysis_data, symbol, security_name, security_type
            )
            
            return result
            
        except Exception as e:
            return {
                'success': False,
                'error': f'AIæ¨èè¿‡ç¨‹å‡ºç°é”™è¯¯: {str(e)}'
            }
    
    def analyze_kdas_state_with_ai(self, processed_data, input_date, symbol, security_type, api_key, model, get_security_name_func):
        """
        ä½¿ç”¨AIåˆ†æKDASçŠ¶æ€
        
        Args:
            processed_data: å¤„ç†åçš„æ•°æ®
            input_date: è¾“å…¥æ—¥æœŸ
            symbol: è¯åˆ¸ä»£ç 
            security_type: è¯åˆ¸ç±»å‹
            api_key: APIå¯†é’¥
            model: AIæ¨¡å‹
            get_security_name_func: è·å–è¯åˆ¸åç§°çš„å‡½æ•°
        """
        if not self.ai_available:
            return {
                'success': False,
                'error': 'AIåŠŸèƒ½ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥kdasåŒ…æ˜¯å¦æ­£ç¡®å®‰è£…',
                'analysis': 'AIåˆ†æåŠŸèƒ½ä¸å¯ç”¨'
            }
        
        try:
            # è·å–è¯åˆ¸åç§°
            security_name = get_security_name_func(symbol, security_type)
            
            analyzer = KDASAnalyzer(api_key, model)
            analysis_result = analyzer.analyze_kdas_state(
                processed_data, input_date, symbol, security_name, security_type
            )
            
            return analysis_result
            
        except Exception as e:
            return {
                'success': False,
                'error': f'AIåˆ†æè¿‡ç¨‹å‡ºç°é”™è¯¯: {str(e)}',
                'analysis': f'åˆ†æå¤±è´¥: {str(e)}'
            }
    
    def format_analysis_text(self, analysis_text):
        """ç»Ÿä¸€çš„åˆ†ææ–‡æœ¬æ ¼å¼åŒ–å‡½æ•°ï¼Œæ•´åˆåŸæœ‰çš„å¤šä¸ªæ ¼å¼åŒ–å‡½æ•°"""
        if not analysis_text or not analysis_text.strip():
            return "æš‚æ— åˆ†æå†…å®¹"
        
        # å°è¯•ä»æ–‡æœ¬ä¸­æå–JSONéƒ¨åˆ†
        json_data = self._extract_json_from_text(analysis_text)
        
        if json_data:
            # å¦‚æœæˆåŠŸæå–å¹¶è§£æJSONï¼Œåˆ™æ ¼å¼åŒ–å±•ç¤º
            return self._format_json_analysis(json_data)
        else:
            # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œä½¿ç”¨åŸæœ‰çš„æ–‡æœ¬æ ¼å¼åŒ–æ–¹æ³•
            return self._format_plain_text_analysis(analysis_text)
    
    def _extract_json_from_text(self, text):
        """ä»æ–‡æœ¬ä¸­æå–JSONéƒ¨åˆ†å¹¶è§£æä¸ºå­—å…¸"""
        try:
            # æ–¹æ³•1ï¼šå°è¯•æ‰¾åˆ°è¢«```jsonåŒ…å›´çš„JSON
            json_match = re.search(r'```json\s*\n(.*?)\n```', text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1).strip()
                return json.loads(json_str)
            
            # æ–¹æ³•2ï¼šå°è¯•æ‰¾åˆ°å¤§æ‹¬å·åŒ…å›´çš„JSON
            json_match = re.search(r'\{.*\}', text, re.DOTALL)
            if json_match:
                json_str = json_match.group().strip()
                return json.loads(json_str)
            
            # æ–¹æ³•3ï¼šå°è¯•ç›´æ¥è§£ææ•´ä¸ªæ–‡æœ¬
            return json.loads(text.strip())
            
        except (json.JSONDecodeError, AttributeError):
            return None
    
    def _format_json_analysis(self, json_data):
        """æ ¼å¼åŒ–JSONæ ¼å¼çš„åˆ†æç»“æœ"""
        if not isinstance(json_data, dict):
            return "åˆ†æç»“æœæ ¼å¼é”™è¯¯"
        
        formatted_content = []
        
        # æŒ‰é¢„å®šä¹‰é¡ºåºå±•ç¤ºå­—æ®µ
        for field_key, (icon, title) in self.field_mapping.items():
            if field_key in json_data:
                content = json_data[field_key]
                if content and str(content).strip():
                    # æ ¼å¼åŒ–å†…å®¹
                    formatted_content.append(f"#### {icon} {title}")
                    formatted_content.append("")
                    
                    # åº”ç”¨æ–‡æœ¬æ ·å¼
                    styled_content = self._apply_text_styling(str(content))
                    formatted_content.append(styled_content)
                    formatted_content.append("")  # æ·»åŠ ç©ºè¡Œåˆ†éš”
        
        # å¤„ç†å…¶ä»–æœªæ˜ å°„çš„å­—æ®µ
        for key, value in json_data.items():
            if key not in self.field_mapping and value and str(value).strip():
                formatted_content.append(f"#### ğŸ”¸ {key}")
                formatted_content.append("")
                styled_content = self._apply_text_styling(str(value))
                formatted_content.append(styled_content)
                formatted_content.append("")
        
        return '\n'.join(formatted_content)
    
    def _format_plain_text_analysis(self, analysis_text):
        """æ ¼å¼åŒ–æ™®é€šæ–‡æœ¬æ ¼å¼çš„åˆ†æç»“æœï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ï¼‰"""
        # é¦–å…ˆå¤„ç†æ•´ä½“ç»“æ„
        formatted_content = []
        
        # æŒ‰è¡Œåˆ†å‰²å¹¶é‡æ–°ç»„ç»‡
        lines = analysis_text.split('\n')
        current_section = []
        
        for line in lines:
            line = line.strip()
            if not line:
                if current_section:
                    # å¤„ç†å½“å‰ç§¯ç´¯çš„æ®µè½
                    section_text = ' '.join(current_section).strip()
                    if section_text:
                        formatted_content.append(self._format_paragraph(section_text))
                    current_section = []
                continue
            
            current_section.append(line)
        
        # å¤„ç†æœ€åä¸€ä¸ªæ®µè½
        if current_section:
            section_text = ' '.join(current_section).strip()
            if section_text:
                formatted_content.append(self._format_paragraph(section_text))
        
        # åˆå¹¶æ‰€æœ‰å†…å®¹
        result = '\n\n'.join(formatted_content)
        
        # å…¨å±€æ ·å¼ä¼˜åŒ–
        result = self._apply_text_styling(result)
        
        return result
    
    def _format_paragraph(self, text):
        """æ ¼å¼åŒ–å•ä¸ªæ®µè½"""
        if not text.strip():
            return ""
        
        # å¤„ç†ä¸»è¦ç« èŠ‚æ ‡é¢˜ï¼ˆå¦‚ï¼š1. **å½“å‰KDASçŠ¶æ€åˆ¤æ–­**ï¼‰
        main_section_match = re.match(r'^(\d+)\.\s*\*\*(.*?)\*\*[:ï¼š]?(.*)', text)
        
        if main_section_match:
            num = main_section_match.group(1)
            title = main_section_match.group(2).strip()
            content = main_section_match.group(3).strip()
            
            icon = self.paragraph_icons.get(num, 'ğŸ”¸')
            
            result = f"#### {icon} {num}. {title}\n"
            if content:
                result += f"\n{content}"
            return result
        
        # å¤„ç†å­æ ‡é¢˜ï¼ˆå¦‚ï¼š**å¤šç©ºåŠ›é‡åˆ†æ**ï¼‰
        subtitle_match = re.match(r'^\*\*(.*?)\*\*[:ï¼š]?(.*)', text)
        if subtitle_match:
            title = subtitle_match.group(1).strip()
            content = subtitle_match.group(2).strip()
            result = f"**ğŸ”¸ {title}**"
            if content:
                result += f"\n\n{content}"
            return result
        
        # å¤„ç†å¼•ç”¨å†…å®¹
        if text.startswith('"') and text.endswith('"'):
            return f"> {text[1:-1]}"
        
        # å¤„ç†åˆ—è¡¨é¡¹
        if text.startswith('- '):
            return f"â€¢ {text[2:]}"
        
        # å¤„ç†æ™®é€šæ®µè½
        return text
    
    def _apply_text_styling(self, text):
        """åº”ç”¨æ–‡æœ¬æ ·å¼ä¼˜åŒ–"""
        for old, new in self.styling_rules:
            # åªæ›¿æ¢ç‹¬ç«‹çš„è¯ï¼Œé¿å…é‡å¤æ›¿æ¢
            text = re.sub(f'(?<!\\*){re.escape(old)}(?!\\*)', new, text)
        
        return text
    
    def run_integrated_analysis(self, security_type, symbol, api_key, model, manual_dates, get_security_name_func, get_security_data_func, calculate_cumulative_vwap_func):
        """
        è¿è¡Œé›†æˆçš„AIåˆ†æï¼ˆåŒ…æ‹¬æ—¥æœŸæ¨èå’ŒçŠ¶æ€åˆ†æï¼‰
        
        Args:
            security_type: è¯åˆ¸ç±»å‹
            symbol: è¯åˆ¸ä»£ç 
            api_key: APIå¯†é’¥
            model: AIæ¨¡å‹
            manual_dates: æ‰‹åŠ¨æ—¥æœŸï¼ˆå¤‡ç”¨ï¼‰
            get_security_name_func: è·å–è¯åˆ¸åç§°çš„å‡½æ•°
            get_security_data_func: è·å–è¯åˆ¸æ•°æ®çš„å‡½æ•°
            calculate_cumulative_vwap_func: è®¡ç®—KDASçš„å‡½æ•°
        """
        if not self.ai_available:
            return {
                'success': False,
                'error': 'AIåŠŸèƒ½ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥kdasåŒ…æ˜¯å¦æ­£ç¡®å®‰è£…',
                'mode': 'ai_unavailable'
            }
        
        try:
            # è·å–è¯åˆ¸åç§°
            security_name = get_security_name_func(symbol, security_type)
            
            # ä½¿ç”¨kdasåŒ…çš„é›†æˆåŠŸèƒ½
            advisor = self.get_ai_advisor_instance(api_key, model)
            if advisor is None:
                raise Exception("æ— æ³•åˆ›å»ºAIé¡¾é—®å®ä¾‹")
            
            # å¼‚æ­¥è°ƒç”¨éœ€è¦åœ¨åŒæ­¥å‡½æ•°ä¸­å¤„ç†
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                kdas_result = loop.run_until_complete(
                    advisor.analyze_all_async(security_type, symbol, api_key, model)
                )
            finally:
                loop.close()
            
            if not kdas_result.get('success', False):
                # å¦‚æœAIåˆ†æå¤±è´¥ï¼Œå›é€€åˆ°æ‰‹åŠ¨æ¨¡å¼
                if manual_dates:
                    df = get_security_data_func(symbol, manual_dates, security_type)
                    processed_data = calculate_cumulative_vwap_func(df, manual_dates)
                    
                    return {
                        'success': True,
                        'data': df,
                        'processed_data': processed_data,
                        'security_name': security_name,
                        'input_dates': manual_dates,
                        'recommendation_result': None,
                        'ai_analysis_result': None,
                        'mode': 'manual_fallback',
                        'ai_error': kdas_result.get('error', 'æœªçŸ¥é”™è¯¯')
                    }
                else:
                    return {
                        'success': False,
                        'error': f'AIåˆ†æå¤±è´¥: {kdas_result.get("error", "æœªçŸ¥é”™è¯¯")}',
                        'mode': 'ai_failed'
                    }
            
            # æˆåŠŸè·å¾—AIæ¨èï¼Œä½¿ç”¨æ¨èçš„æ—¥æœŸé‡æ–°è·å–æ•°æ®å’Œè®¡ç®—KDAS
            recommended_dates_dict = kdas_result.get('input_dates', {})
            df = get_security_data_func(symbol, recommended_dates_dict, security_type)
            processed_data = calculate_cumulative_vwap_func(df, recommended_dates_dict)
            
            return {
                'success': True,
                'data': df,
                'processed_data': processed_data,
                'security_name': security_name,
                'input_dates': recommended_dates_dict,
                'recommendation_result': kdas_result.get('recommendation'),
                'ai_analysis_result': kdas_result.get('analysis'),
                'mode': 'ai_integrated',
                'recommended_dates': kdas_result.get('recommended_dates', [])
            }
            
        except Exception as e:
            # AIåˆ†æå‡ºé”™ï¼Œå¦‚æœæœ‰æ‰‹åŠ¨æ—¥æœŸåˆ™å›é€€
            if manual_dates:
                try:
                    security_name = get_security_name_func(symbol, security_type)
                    df = get_security_data_func(symbol, manual_dates, security_type)
                    processed_data = calculate_cumulative_vwap_func(df, manual_dates)
                    
                    return {
                        'success': True,
                        'data': df,
                        'processed_data': processed_data,
                        'security_name': security_name,
                        'input_dates': manual_dates,
                        'recommendation_result': None,
                        'ai_analysis_result': None,
                        'mode': 'manual_fallback',
                        'ai_error': str(e)
                    }
                except Exception as fallback_error:
                    return {
                        'success': False,
                        'error': f'AIåˆ†æå¤±è´¥ä¸”æ‰‹åŠ¨æ¨¡å¼ä¹Ÿå¤±è´¥: AIé”™è¯¯={str(e)}, æ‰‹åŠ¨é”™è¯¯={str(fallback_error)}',
                        'mode': 'total_failure'
                    }
            else:
                return {
                    'success': False,
                    'error': f'AIé›†æˆåˆ†æå¤±è´¥: {str(e)}',
                    'mode': 'ai_failed'
                }

# === å…¨å±€AIåˆ†æç®¡ç†å™¨å®ä¾‹ ===
ai_manager = AIAnalysisManager()

# === å‘åå…¼å®¹çš„å…¨å±€å‡½æ•°æ¥å£ ===
def get_ai_advisor_instance(api_key, model):
    """è·å–AIé¡¾é—®å®ä¾‹ - å‘åå…¼å®¹æ¥å£"""
    return ai_manager.get_ai_advisor_instance(api_key, model)

def generate_ai_recommendation(symbol, security_type, api_key, model):
    """ç”ŸæˆAIæ—¥æœŸæ¨è - å‘åå…¼å®¹æ¥å£"""
    # éœ€è¦å¯¼å…¥æ•°æ®å¤„ç†å‡½æ•°
    from .data_handler import get_security_name, get_security_data
    return ai_manager.generate_ai_recommendation(symbol, security_type, api_key, model, get_security_name, get_security_data)

def analyze_kdas_state_with_ai(processed_data, input_date, symbol, security_type, api_key, model):
    """ä½¿ç”¨AIåˆ†æKDASçŠ¶æ€ - å‘åå…¼å®¹æ¥å£"""
    # éœ€è¦å¯¼å…¥æ•°æ®å¤„ç†å‡½æ•°
    from .data_handler import get_security_name
    return ai_manager.analyze_kdas_state_with_ai(processed_data, input_date, symbol, security_type, api_key, model, get_security_name)

def format_analysis_text(analysis_text):
    """ç»Ÿä¸€çš„åˆ†ææ–‡æœ¬æ ¼å¼åŒ–å‡½æ•° - å‘åå…¼å®¹æ¥å£"""
    return ai_manager.format_analysis_text(analysis_text)

# === å†…éƒ¨å‡½æ•°çš„å‘åå…¼å®¹æ¥å£ ===
def _extract_json_from_text(text):
    """ä»æ–‡æœ¬ä¸­æå–JSONéƒ¨åˆ† - å‘åå…¼å®¹æ¥å£"""
    return ai_manager._extract_json_from_text(text)

def _format_json_analysis(json_data):
    """æ ¼å¼åŒ–JSONæ ¼å¼çš„åˆ†æç»“æœ - å‘åå…¼å®¹æ¥å£"""
    return ai_manager._format_json_analysis(json_data)

def _format_plain_text_analysis(analysis_text):
    """æ ¼å¼åŒ–æ™®é€šæ–‡æœ¬æ ¼å¼çš„åˆ†æç»“æœ - å‘åå…¼å®¹æ¥å£"""
    return ai_manager._format_plain_text_analysis(analysis_text)

def _format_paragraph(text):
    """æ ¼å¼åŒ–å•ä¸ªæ®µè½ - å‘åå…¼å®¹æ¥å£"""
    return ai_manager._format_paragraph(text)

def _apply_text_styling(text):
    """åº”ç”¨æ–‡æœ¬æ ·å¼ä¼˜åŒ– - å‘åå…¼å®¹æ¥å£"""
    return ai_manager._apply_text_styling(text)

# === AIå¯ç”¨æ€§æ£€æŸ¥ ===
AI_ADVISOR_AVAILABLE = ai_manager.ai_available 